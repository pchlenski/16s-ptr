""" Scripts for solving an OTU table from a DB """

from collections import defaultdict
from typing import Tuple
import pandas as pd
import numpy as np
from .matrix_solver import OTUSolver
from .database import RnaDB


def _find_candidates(sample: pd.Series, db: RnaDB) -> Tuple[pd.DataFrame, list]:
    """
    Given a sample (indexed by MD5 hash IDs), find sequences that:
    * Are in the relevant RnaDB object database
    * Have non-zero read count
    * Have multiple MD5s in a sample that can match to the same genome

    Args:
    -----
    sample: pd.Series
        A single column from an OTU table, indexed by MD5 hash IDs
    db: RnaDB
        A database object specified in database.py

    Returns:
    --------
    coverages: pd.DataFrame
        A dataframe of coverages for each MD5 hash ID after filtering
    candidates: list
        A list of genome IDs that are candidates for solving

    Raises:
    -------
    TODO
    """

    # Pass 1: find all genomes with nonzero read counts
    md5s = sample[sample > 0].index
    # genome_hits = [(find_genomes_by_md5(md5, db)) for md5 in md5s]
    genome_hits = [db.find_genomes_by_md5(md5) for md5 in md5s]
    counts = defaultdict(lambda: 0)

    # Pass 2: find all genomes with more than 1 md5 matching
    for hit in genome_hits:
        for genome in hit:
            counts[genome] += 1
    genomes_filtered = [key for key in counts if counts[key] > 1]

    # Pass 3: filter to correct number
    candidates = []
    keep_md5s = set()
    for genome in genomes_filtered:
        unused_str = "hello world"
        # genome_md5s = set(db[db["genome"] == genome]["md5"].unique())
        genome_md5s = set(db[genome]["md5"].unique())
        n_seqs = len(genome_md5s)
        if n_seqs == counts[genome]:
            candidates.append(genome)
            keep_md5s = keep_md5s | genome_md5s

    # Filter table
    filtered_index = [i for i in sample.index if i in keep_md5s]

    return sample.loc[filtered_index], candidates


def solve_all(
    otu_table_path: str,
    db_path: str = None,
    left_adapter: str = None,
    right_adapter: str = None,
    true_values: str = None,
) -> Tuple[pd.DataFrame, pd.DataFrame]:
    """
    Calls all the other functions to solve a TSV of coverages with a database

    Args:
    -----
    otu_table_path: str
        Path to a TSV of coverages, indexed by MD5 hash IDs. This can be
        generated by process_samples.py
    db_path: str
        Path to a pickled RnaDB object. If not specified, will generate a new
        database from left_adapter and
        right_adapter.
    left_adapter: str
        The 3' adapter used to sequence the RNAs.
    right_adapter: str
        The 5' adapter used to sequence the RNAs.
    true_values: str
        Path to a TSV of true PTRs. Should have the same columns as the OTU
        table and be indexed on genome ID.

    Returns:
    --------
    ptrs: pd.DataFrame
        A dataframe of inferred PTRs, indexed by genome ID and sample ID.
    abundances: pd.DataFrame
        A dataframe of inferred abundances, indexed by genome ID and sample ID.

    Raises:
    -------
    TODO
    """

    # Produce/load an RnaDB object for inference
    if db_path is not None:
        db = RnaDB(load=db_path)
    else:
        db = RnaDB(left_primer=left_adapter, right_primer=right_adapter)
    table = pd.read_table(otu_table_path, index_col=0)

    # Initialize output table
    out = pd.DataFrame(columns=["sample", "genome", "ptr", "abundance"])

    # Solve each sample
    for column in table.columns:
        sample = table[column]
        coverages, candidates = _find_candidates(sample, db)
        if len(candidates) > 0:
            # Get genome objects (containing OOR and 16S RNA coordinates)
            print(column)
            print(candidates)
            genomes, all_seqs = db.generate_genome_objects(candidates)

            # Reorder according to generate_genome_objects
            sample = sample.loc[all_seqs]

            # Solve for PTRs
            solver = OTUSolver(genomes, coverages=coverages.values)
            solver.train(lr=0.001, tolerance=0.0001, verbose=True)
            print(
                "Abundances", np.exp(solver.a_hat), "PTRs", np.exp(solver.b_hat)
            )
            print(
                "True",
                solver.coverages,
                "Predicted",
                solver.compute_coverages(solver.a_hat, solver.b_hat),
            )
            print()

            # Add to output table
            # TODO: test that this actually works
            out = out.append(
                pd.DataFrame(
                    {
                        "sample": column,
                        "genome": candidates,
                        "ptr": np.exp(solver.b_hat),
                        "abundance": np.exp(solver.a_hat),
                    }
                )
            )

    # Return output tables
    # TODO: test that this actually works
    ptrs = out.pivot(index="genome", columns="sample", values="ptr")
    abundances = out.pivot(index="genome", columns="sample", values="abundance")

    return ptrs, abundances
